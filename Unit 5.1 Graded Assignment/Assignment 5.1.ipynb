{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "36abef47-5930-46fe-9138-4affdf64d864",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import IntegerType\n",
    "from pyspark.sql.functions import date_format, avg, max, desc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af8b0eb-9889-44de-b1c1-42564ea38ce3",
   "metadata": {},
   "source": [
    "# Creating spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "5a4e3a1b-f635-46c9-904c-a0e7d1254511",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "scSpark = SparkSession.builder.appName(\"Store Analysis\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebf8068e-be30-450c-8a46-309c826ff177",
   "metadata": {},
   "source": [
    "# Reading , Merging and Formatting our csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "639c88b2-280d-45e0-8e7c-7268ac6d2468",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transactions_merged_df = scSpark.read.csv(\"./store_transactions/transactions_*.csv\", inferSchema=True, header=True)\n",
    "\n",
    "customers_df = scSpark.read.csv(\"customers.csv\", inferSchema=True, header=True)\n",
    "products_df = scSpark.read.csv(\"products.csv\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88726e50-97e8-47ce-9df6-f38d9c862f10",
   "metadata": {},
   "source": [
    "# Printing our data types of our columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "03dc86dd-8492-4637-9575-8a73cfaff15b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- StoreId: integer (nullable = true)\n",
      " |-- TransactionId: integer (nullable = true)\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- ProductId: integer (nullable = true)\n",
      " |-- Quantity: integer (nullable = true)\n",
      " |-- TransactionTime: timestamp (nullable = true)\n",
      "\n",
      "root\n",
      " |-- ProductId: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Category: string (nullable = true)\n",
      " |-- UnitPrice: double (nullable = true)\n",
      "\n",
      "root\n",
      " |-- CustomerId: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Email: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_merged_df.printSchema()\n",
    "products_df.printSchema()\n",
    "customers_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dce9eee-1fee-4b6d-8231-a1aeaa49f22e",
   "metadata": {},
   "source": [
    "# Displaying our processed File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "18e58026-93e1-466f-b0e2-d3572a1ac779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+----------+---------+--------+-------------------+\n",
      "|StoreId|TransactionId|CustomerId|ProductId|Quantity|    TransactionTime|\n",
      "+-------+-------------+----------+---------+--------+-------------------+\n",
      "|      3|          454|        35|        3|       3|2022-12-23 17:36:11|\n",
      "|      3|          524|        37|        9|      11|2022-12-23 22:02:51|\n",
      "|      3|          562|         4|        3|       4|2022-12-23 02:51:50|\n",
      "|      3|          581|        35|       14|      56|2022-12-23 17:05:54|\n",
      "|      3|          200|        34|       15|      24|2022-12-23 07:15:01|\n",
      "+-------+-------------+----------+---------+--------+-------------------+\n",
      "\n",
      "+---------+------------+--------+---------+\n",
      "|ProductId|        Name|Category|UnitPrice|\n",
      "+---------+------------+--------+---------+\n",
      "|        1|  Red Shorts|  Shorts|    89.75|\n",
      "|        2|White Shorts|  Shorts|    89.27|\n",
      "|        3| Blue Shorts|  Shorts|   118.88|\n",
      "|        4|Green Shorts|  Shorts|   121.43|\n",
      "|        5|Black Shorts|  Shorts|    74.58|\n",
      "+---------+------------+--------+---------+\n",
      "\n",
      "+----------+--------------+--------------------+\n",
      "|CustomerId|          Name|               Email|\n",
      "+----------+--------------+--------------------+\n",
      "|         1|Emilia Pedraza|emilia.pedraza@ex...|\n",
      "|         2|  Thies Blümel|thies.blumel@exam...|\n",
      "|         3| بهاره علیزاده|bhrh.aalyzdh@exam...|\n",
      "|         4| Alevtin Paska|alevtin.paska@exa...|\n",
      "|         5|Charlotte Wong|charlotte.wong@ex...|\n",
      "+----------+--------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "transactions_merged_df.limit(5).show()\n",
    "products_df.limit(5).show()\n",
    "customers_df.limit(5).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71c612e-6e4c-4ce4-8cd3-aecfb0b1dae4",
   "metadata": {},
   "source": [
    "# What are the daily total sales for the store with id 1?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "92e203a3-3912-41da-bf0e-cc10b8558be5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+------------------+\n",
      "|TransactionTime| Total Daily Sales|\n",
      "+---------------+------------------+\n",
      "|     2022-12-23|41264.000000000015|\n",
      "+---------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# filtering out only the rows with storeId 1 from transactions table and then selecting productid, quantity, Transactiontime columns from it\n",
    "df_tran_store1 = transactions_merged_df.filter(transactions_merged_df.StoreId ==1).select(\"ProductId\",\"Quantity\",\"TransactionTime\")\n",
    "\n",
    "# this line will add the column with only date(removing time) and reformatting the date to string.\n",
    "df_tran_store1 = df_tran_store1.withColumn(\"TransactionTime\", date_format(\"TransactionTime\" ,\"yyyy-MM-dd\"))\n",
    "\n",
    "# join the products table column product ID and unit price, on product id which will state the rows in parallel\n",
    "# manner according to the product id. using inner will only state those rows matched on transaction store productid\n",
    "\n",
    "df = df_tran_store1.join(products_df.select(\"ProductId\",\"UnitPrice\"), on = \"ProductId\", how = \"inner\")\n",
    "\n",
    "# will add the column Total sales with vaulues of ,product of unit price and quantity which will gives us sales of every row specified\n",
    "df = df.withColumn(\"Total_SALES\", col(\"UnitPrice\").cast(\"double\") * col(\"Quantity\").cast(\"double\"))\n",
    "\n",
    "# this will give the output we want by grouping the dates and calculating the sum of daily sales of the same date and naming it \n",
    "#Total daily sales\n",
    "\n",
    "daily_sales = df.groupBy(\"TransactionTime\").agg(sum(\"Total_SALES\").alias(\"Total Daily Sales\"))\n",
    "#df.printSchema()\n",
    "#df.show()\n",
    "daily_sales.show()\n",
    "#df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "148358c5-baed-460b-842e-92549e20d1ea",
   "metadata": {},
   "source": [
    "As we can see our total daily sales are listed above. AS there was only one day sales of store id 1 in the original data so it would list only 1 day sales with its specified Date"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d31b30a-e389-4e24-83ab-654c194cc7c1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# What are the mean sales for the store with id 2?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "7176ebec-e815-4711-bbe0-469a9f95cabd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+-----------------+\n",
      "|TransactionTime|  Daily Avg Sales|\n",
      "+---------------+-----------------+\n",
      "|     2022-12-23|513.4598039215689|\n",
      "+---------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# almost all the steps are same just some changes are made changes the table and the store id etc. \n",
    "\n",
    "df_tran_store2 = transactions_merged_df.filter(transactions_merged_df.StoreId ==2).select(\"ProductId\",\"Quantity\",\"TransactionTime\")\n",
    "df_tran_store2 = df_tran_store2.withColumn(\"TransactionTime\", date_format(\"TransactionTime\" ,\"yyyy-MM-dd\"))\n",
    "\n",
    "df1 = df_tran_store2.join(products_df.select(\"ProductId\",\"UnitPrice\"), on = \"ProductId\", how = \"inner\")\n",
    "df1 = df1.withColumn(\"Total_SALES\", col(\"UnitPrice\").cast(\"double\") * col(\"Quantity\").cast(\"double\"))\n",
    "\n",
    "# this time we will us avg function to get avg sales on each day\n",
    "Avg_sale = df1.groupBy(\"TransactionTime\").agg(avg(\"Total_SALES\").alias(\"Daily Avg Sales\"))\n",
    "Avg_sale.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71408363-6db8-4069-a27e-8c01e01414b3",
   "metadata": {},
   "source": [
    "As we can see our Avg daily sales are listed above. AS there was only one day sales of store id 2 in the original data so it would list only 1 day sales with its specified Date."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f810a0-8670-492e-b074-4f2b80c8e54d",
   "metadata": {},
   "source": [
    "# What is the email of the client who spent the most when summing up purchases from all of the stores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "7b05b348-f6b1-4c24-9437-1def3beda573",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'dwayne.johnson@gmail.com'"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# almost all the steps are same just some changes are made changes the table and the store id etc. \n",
    "\n",
    "df_trans_all = transactions_merged_df.select(\"ProductId\",\"Quantity\",\"CustomerId\")\n",
    "\n",
    "df2 = df_trans_all.join(customers_df.select(\"CustomerId\",\"Email\"), on = \"CustomerId\", how = \"inner\")\n",
    "df2 = df2.join(products_df.select(\"ProductId\",\"UnitPrice\"), on = \"ProductId\", how = \"inner\")\n",
    "df2 = df2.withColumn(\"Customer_purchases\", col(\"UnitPrice\").cast(\"double\") * col(\"Quantity\").cast(\"double\"))\n",
    "\n",
    "# this time we have group by customer id, summing the customer purchases, which was also the same product of price and quantiy to get \n",
    "# the sales price of every row\n",
    "customer_purchases = df2.groupBy(\"CustomerId\",\"Email\").agg(sum(\"Customer_purchases\").alias(\"customer_purchases\"))\n",
    "\n",
    "# from customer purchases after grouping, we are ordering by descing order and get the email of that person with the highest value or highes purchases\n",
    "highest_val = customer_purchases.orderBy(desc(\"customer_purchases\")).first()[\"Email\"]\n",
    "\n",
    "\n",
    "#customer_purchases.show(100)\n",
    "highest_val"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95d5aba-8456-4218-af56-9faa2c858753",
   "metadata": {},
   "source": [
    "dwayne.johnson@gmail.com is the email of the client spent the most summing up from all stores. spent 10653.08 on his total purchases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761aa03f-855d-40fd-8be1-e700749f5a29",
   "metadata": {},
   "source": [
    "# Which 5 products are most frequently bought across all stores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "97469fbe-4019-4779-85df-6598df9f9578",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-------------+-----+\n",
      "|ProductId|         Name|count|\n",
      "+---------+-------------+-----+\n",
      "|        2| White Shorts|   20|\n",
      "|        5| Black Shorts|    9|\n",
      "|       19| Green jacket|    9|\n",
      "|       15|White t-shirt|    8|\n",
      "|        1|   Red Shorts|    7|\n",
      "+---------+-------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# almost all the steps are same just some changes are made changes the table and the store id etc. \n",
    "# selecting all the necessary columns as done always matching and comparing on transaction table product id \n",
    "df3 = df_trans_all.join(products_df.select(\"ProductId\",\"Name\"), on = \"ProductId\", how = \"inner\")\n",
    "\n",
    "#this will group the transaction on id add a column count counting the number of transactions\n",
    "product_count = df3.groupBy('ProductId','Name').count()\n",
    "\n",
    "# this will arrange in descending order\n",
    "top_products = product_count.orderBy(desc(\"count\"))\n",
    "# and will retrieve top 5 rows which will be 5 most frequently bought\n",
    "top_5_products = top_products.limit(5)\n",
    "\n",
    "top_5_products.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81ed59d-a6a1-43c4-8e57-b6c43ad10e55",
   "metadata": {},
   "source": [
    "These 5 products are most frequently bought accross all stores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d20237-d9d2-4f9a-8ea7-33dae5e1a82b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
